version: '3'

services:
  h2ogpt:
    image: gcr.io/vorvan/h2oai/h2ogpt-runtime:0.1.0
    restart: always
    shm_size: '2gb'
    depends_on:
      - vllm
    ports:
      - '7860:7860'
    volumes:
      - cache:/workspace/.cache
      - save:/workspace/save
    networks:
      - h2ogpt
    command:
      - /workspace/generate.py
      - --inference_server="vllm:vllm:5000"
      - --base_model=h2oai/h2ogpt-4096-llama2-7b-chat
      - --langchain_mode=UserData
    deploy:
      resources:
        reservations:
          devices:
          - driver: nvidia
            device_ids: ['2', '3']
            capabilities: [gpu]

  vllm:
    image: gcr.io/vorvan/h2oai/h2ogpt-runtime:0.1.0
    restart: always
    shm_size: '64gb'
    expose:
      - 5000
    volumes:
      - cache:/workspace/.cache
    networks:
      - h2ogpt
    entrypoint: /h2ogpt_conda/vllm_env/bin/python3.10
    command:
      - -m
      - vllm.entrypoints.openai.api_server
      - --port=5000
      - --host=0.0.0.0
      - --model=h2oai/h2ogpt-4096-llama2-7b-chat
      - --tokenizer=hf-internal-testing/llama-tokenizer
      - --tensor-parallel-size=2
      - --seed=1234
      - --trust-remote-code
      - --download-dir=/workspace/.cache/huggingface/hub
    environment:
      - NCCL_IGNORE_DISABLED_P2P=1
    deploy:
      resources:
        reservations:
          devices:
          - driver: nvidia
            device_ids: ['0', '1']
            capabilities: [gpu]

volumes:
  cache:
  save:
networks:
  h2ogpt:
